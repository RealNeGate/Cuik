(namespace x86)

#if 0
// (node NAME EXTRA_TYPE)
(node shl X86MemOp)
(node shlx X86MemOp)

pat (TB_SHL dt=$dt ___ $lhs $rhs)
where "ctx->features.x64 & TB_FEATURE_X64_BMI2"
=> (x86_shlx dt=$dt ___ ___ $lhs $rhs)

pat (TB_SHL dt=$dt ___ (TB_LOAD $ctrl $mem ($lhs: x86_MEMORY ...)) $rhs)
where "ctx->features.x64 & TB_FEATURE_X64_BMI2"
=> (x86_shlx dt=$dt $ctrl $mem $lhs $rhs mode=MODE_LD)

pat (TB_SHL dt=$dt ___ $lhs $rhs) => (x86_shl dt=$dt ___ ___ $rhs $lhs)

pat (TB_SHL dt=$dt ___ ($lhs: TB_ICONST ...) $rhs) => (x86_shl dt=$dt ___ ___ $lhs flags="OP_IMMEDIATE" imm="as_int32($rhs)")

(node COND X86MemOp)
(node cmp X86MemOp)
(node test X86MemOp)
(node ucomi X86MemOp)

// compares
#define CMP_OP(op_name, cc) \
pat (op_name cmp_dt=$dt ___ $lhs $rhs) where "TB_IS_BOOL_INT_PTR($dt)" => (x86_COND dt=TB_TYPE_I8 (x86_cmp dt=TB_TYPE_I64 ___ ___ $rhs $lhs extra_dt=$dt) cond=cc) \
pat (op_name cmp_dt=$dt ___ $lhs ($rhs: TB_ICONST ...)) where "TB_IS_BOOL_INT_PTR($dt) && fits_into_int32($dt, $rhs)" => (x86_COND dt=TB_TYPE_I8 (x86_cmp dt=TB_TYPE_I64 ___ ___ $lhs flags="OP_IMMEDIATE" imm="as_int32($rhs)" extra_dt=$dt) cond=cc)

CMP_OP(TB_CMP_SLE, LE)
CMP_OP(TB_CMP_SLT, L)
CMP_OP(TB_CMP_ULE, BE)
CMP_OP(TB_CMP_ULT, B)
CMP_OP(TB_CMP_EQ,  E)
CMP_OP(TB_CMP_NE,  NE)

pat (TB_IF ...) => "X"
pat (TB_IF $ctrl (x86_COND $cmp)) => "X"
pat (TB_IF $ctrl $x) => "X"
#else
// *******************************
// memory operands
// *******************************
(node MEMORY X86MemOp)

// [base + index]
pat (TB_PTR_OFFSET ___ $base $index)
=> (x86_MEMORY flags=OP_INDEXED $base $index scale=0)

// [base + disp]
pat (TB_PTR_OFFSET ___ $base ($imm: TB_ICONST ...))
where "fits_into_int32(TB_TYPE_I64, $imm)"
=> (x86_MEMORY $base disp="as_int32($imm)")

// [base + index + disp]
pat (TB_PTR_OFFSET ___ $base (TB_ADD ___ $index ($imm: TB_ICONST ...)))
where "fits_into_int32(TB_TYPE_I64, $imm)"
=> (x86_MEMORY $base $index flags=OP_INDEXED disp="as_int32($imm)")

// [base + index*scale + disp]
pat (TB_PTR_OFFSET ___ $base (TB_ADD ___ (TB_SHL ___ $index ($scale: TB_ICONST ...)) ($disp: TB_ICONST ...)))
where "fits_into_scale($scale) && fits_into_int32(TB_TYPE_I64, $disp)"
=> (x86_MEMORY dt=TB_TYPE_PTR flags=OP_INDEXED $base $index scale="as_int32($scale)" disp="as_int32($disp)")

// [base + index*scale]
pat (TB_PTR_OFFSET ___ $base (TB_SHL ___ $index ($scale: TB_ICONST ...)))
where "fits_into_scale($scale)"
=> (x86_MEMORY dt=TB_TYPE_PTR flags=OP_INDEXED $base $index scale="as_int32($scale)")

// [base + index*scale + disp]
pat (TB_PTR_OFFSET ___ $base (TB_ADD ___ (TB_SHL ___ $index ($scale: TB_ICONST ...)) ($disp: TB_ICONST ...)))
where "fits_into_scale($scale) && fits_into_int32(TB_TYPE_I64, $disp)"
=> (x86_MEMORY flags=OP_INDEXED $base $index scale="as_int32($scale)" disp="as_int32($disp)")

pat (TB_LOCAL $root stack_pos=$disp) => (x86_MEMORY "ctx->frame_ptr" disp=$disp)

// [symbol]
pat (TB_SYMBOL $root sym=$sym) => (x86_MEMORY (TB_MACH_SYMBOL $root sym=$sym))

// [symbol + offset]
pat (TB_PTR_OFFSET ___ (TB_SYMBOL $root sym=$sym) $offset)
=> (x86_MEMORY (x86_lea dt=TB_TYPE_PTR ___ ___ (TB_MACH_SYMBOL $root sym=$sym) mode=MODE_LD) $offset flags=OP_INDEXED)

// [symbol + disp]
pat (TB_PTR_OFFSET ___ (TB_SYMBOL $root sym=$sym) ($disp: TB_ICONST ...))
where "fits_into_int32(TB_TYPE_I64, $disp)"
=> (x86_MEMORY (TB_MACH_SYMBOL $root sym=$sym) disp="as_int32($disp)")

// using an lea as a memory operand is kinda useful... swag :p
subpat (x86_lea ___ ___ $base disp=$disp) => (x86_MEMORY $base disp=$disp)
subpat (x86_lea ___ ___ $base $index scale=$scale disp=$disp flags=$flags) where "$flags==OP_INDEXED" => (x86_MEMORY $base $index flags=OP_INDEXED scale=$scale disp=$disp)

// [rsp + offset]
pat (TB_PTR_OFFSET ___ (x86_MEMORY (TB_MACH_FRAME_PTR ...) flags=$flags disp=$disp) ($addend: TB_ICONST ...))
=> (x86_MEMORY "ctx->frame_ptr" flags=$flags disp="$disp + as_int32($addend)")

// *******************************
// FLAGS
// *******************************
(node COND X86MemOp)
(node cmp X86MemOp)
(node test X86MemOp)
(node ucomi X86MemOp)

// compares
#define CMP_OP(op_name, cc) \
pat (op_name cmp_dt=$dt ___ $lhs $rhs) where "TB_IS_BOOL_INT_PTR($dt)" => (x86_COND dt=TB_TYPE_I8 (x86_cmp dt=TB_TYPE_I64 ___ ___ $rhs $lhs extra_dt=$dt) cond=cc) \
pat (op_name cmp_dt=$dt ___ $lhs ($rhs: TB_ICONST ...)) where "TB_IS_BOOL_INT_PTR($dt) && fits_into_int32($dt, $rhs)" => (x86_COND dt=TB_TYPE_I8 (x86_cmp dt=TB_TYPE_I64 ___ ___ $lhs flags="OP_IMMEDIATE" imm="as_int32($rhs)" extra_dt=$dt) cond=cc)

CMP_OP(TB_CMP_SLE, LE)
CMP_OP(TB_CMP_SLT, L)
CMP_OP(TB_CMP_ULE, BE)
CMP_OP(TB_CMP_ULT, B)
CMP_OP(TB_CMP_EQ,  E)
CMP_OP(TB_CMP_NE,  NE)

pat (TB_CMP_FLT cmp_dt=$dt ___ $lhs $rhs) => (x86_COND dt=TB_TYPE_I8 (x86_ucomi dt=TB_TYPE_I64 ___ ___ $rhs $lhs extra_dt=$dt) cond=B)
pat (TB_CMP_FLE cmp_dt=$dt ___ $lhs $rhs) => (x86_COND dt=TB_TYPE_I8 (x86_ucomi dt=TB_TYPE_I64 ___ ___ $rhs $lhs extra_dt=$dt) cond=BE)
pat (TB_CMP_EQ  cmp_dt=$dt ___ $lhs $rhs) where "TB_IS_FLOAT_TYPE($dt)" => (x86_COND dt=TB_TYPE_I8 (x86_ucomi dt=TB_TYPE_I64 ___ ___ $rhs $lhs extra_dt=$dt) cond=E)
pat (TB_CMP_NE  cmp_dt=$dt ___ $lhs $rhs) where "TB_IS_FLOAT_TYPE($dt)" => (x86_COND dt=TB_TYPE_I8 (x86_ucomi dt=TB_TYPE_I64 ___ ___ $rhs $lhs extra_dt=$dt) cond=NE)

pat (TB_CMP_EQ cmp_dt=$dt ___ $lhs ($rhs: TB_ICONST ...)) where "TB_IS_INT_OR_PTR($dt) && TB_NODE_GET_EXTRA_T($rhs, TB_NodeInt)->value == 0" => (x86_COND dt=TB_TYPE_I8 (x86_test dt=TB_TYPE_I64 ___ ___ $lhs $lhs extra_dt=$dt) cond=E)
pat (TB_CMP_NE cmp_dt=$dt ___ $lhs ($rhs: TB_ICONST ...)) where "TB_IS_INT_OR_PTR($dt) && TB_NODE_GET_EXTRA_T($rhs, TB_NodeInt)->value == 0" => (x86_COND dt=TB_TYPE_I8 (x86_test dt=TB_TYPE_I64 ___ ___ $lhs $lhs extra_dt=$dt) cond=NE)

(node jcc X86MemOp)
(node jmp_MULTI X86MemOp)

/* canonicalize the if-shaped branches */
pat (TB_IF ...) => "isel_if_branch(ctx, f, n)"
pat (TB_AFFINE_LATCH ...) => "isel_if_branch(ctx, f, n)"

/* standard two-way branches */
pat (TB_IF dt=$dt $ctrl (x86_COND $cmp cond=$cond)) => (x86_jcc dt=TB_TYPE_TUPLE $ctrl $cmp cond=$cond prob="if_prob(n)")
pat (TB_IF dt=$dt $ctrl $x) => (x86_jcc dt=TB_TYPE_TUPLE $ctrl (x86_test dt=TB_TYPE_I64 ___ ___ $x $x extra_dt="n->inputs[1]->dt") cond=NE prob="if_prob(n)")
pat (TB_IF dt=$dt $ctrl (TB_AND ___ $x $y)) => (x86_jcc dt=TB_TYPE_TUPLE $ctrl (x86_test dt=TB_TYPE_I64 ___ ___ $x $y extra_dt="n->inputs[1]->dt") cond=NE prob="if_prob(n)")
/* multi-way branches */ \
pat (TB_BRANCH dt=$dt $ctrl $x) => "isel_multi_way_branch(ctx, f, n)"

// if we don't get rid of the "condition" by merging it with something
// else then it's being directly used.
(node setcc X86MemOp)
pat (x86_COND $cmp cond=$cond) => (x86_setcc dt=TB_TYPE_I8 ___ ___ $cmp cond=$cond)

(node cmovcc X86MemOp)
pat (TB_SELECT dt=$dt ___ $pred $a $b) => (x86_cmovcc dt=$dt ___ ___ $b $a (x86_test dt=TB_TYPE_I64 ___ ___ $pred $pred extra_dt="n->inputs[1]->dt") cond=NE)
pat (TB_SELECT dt=$dt ___ (x86_COND $cmp cond=$cond) $a $b) => (x86_cmovcc dt=$dt ___ ___ $b $a $cmp cond=$cond)

(node bt X86MemOp)
pat (TB_AND dt=$dt ___ (TB_SHL ___ ($con: TB_ICONST ...) $y) $x) where "as_int32($con) == 1" => (x86_COND dt=TB_TYPE_I8 (x86_bt dt=TB_TYPE_I64 ___ ___ $y $x extra_dt=$dt) cond=B)

(node adc X86MemOp)
pat (x86_cmovcc dt=$dt ___ ___ $x (TB_ADD ___ $y ($con: TB_ICONST ...)) $pred) where "as_int32($con) == 1 && TB_NODE_GET_EXTRA_T(n, X86MemOp)->cond == B" => (x86_adc dt=$dt ___ ___ $x $pred flags="OP_IMMEDIATE" imm="0")

// *******************************
// misc
// *******************************
(node call X86MemOp)
pat (TB_CALL $ctrl $mem (x86_MEMORY ($sym: TB_MACH_SYMBOL ...)) $REST) => (x86_call dt=TB_TYPE_TUPLE $ctrl $mem $sym $REST proto="TB_NODE_GET_EXTRA_T(n, TB_NodeCall)->proto")
pat (TB_CALL $ctrl $mem $target $REST) => (x86_call dt=TB_TYPE_TUPLE $ctrl $mem $target $REST mode=MODE_LD proto="TB_NODE_GET_EXTRA_T(n, TB_NodeCall)->proto")

pat (TB_VA_START ...) => "isel_va_start(ctx, f, n)"

// *******************************
// BMI2
// *******************************
#define BMI2_OP(op_name, mnemonic) \
(node mnemonic X86MemOp) \
pat (op_name dt=$dt ___ $lhs $rhs) where "ctx->features.x64 & TB_FEATURE_X64_BMI2" => (x86_ ## mnemonic dt=$dt ___ ___ $lhs $rhs) \
pat (op_name dt=$dt ___ (TB_LOAD $ctrl $mem ($lhs: x86_MEMORY ...)) $rhs) where "ctx->features.x64 & TB_FEATURE_X64_BMI2" => (x86_ ## mnemonic dt=$dt $ctrl $mem $lhs $rhs mode=MODE_LD) \

BMI2_OP(TB_SHL, shlx)
BMI2_OP(TB_SHR, shrx)
BMI2_OP(TB_SAR, sarx)

// *******************************
// integer ops
// *******************************
(node mov X86MemOp)
(node lea X86MemOp)

pat ($lhs: x86_MEMORY ...) => (x86_lea dt=TB_TYPE_PTR ___ ___ $lhs mode=MODE_LD)

pat (TB_LOAD dt=$dt $ctrl $mem $addr) where "TB_IS_INT_OR_PTR($dt)" => (x86_mov dt=$dt $ctrl $mem $addr mode=MODE_LD)
pat (TB_LOAD dt=$dt $ctrl $mem ($lhs: x86_MEMORY ...)) where "TB_IS_INT_OR_PTR($dt)" => (x86_mov dt=$dt $ctrl $mem $lhs mode=MODE_LD)

pat (TB_STORE $ctrl $mem $addr $val) where "TB_IS_INT_OR_PTR($val->dt)" => (x86_mov dt=TB_TYPE_MEMORY $ctrl $mem $addr $val mode=MODE_ST extra_dt="n->inputs[3]->dt")
pat (TB_STORE $ctrl $mem ($lhs: x86_MEMORY ...) $val) where "TB_IS_INT_OR_PTR($val->dt)" => (x86_mov dt=TB_TYPE_MEMORY $ctrl $mem $lhs $val mode=MODE_ST extra_dt="n->inputs[3]->dt")
pat (TB_STORE $ctrl $mem ($lhs: x86_MEMORY ...) ($val: TB_ICONST ...)) where "TB_IS_INT_OR_PTR($val->dt) && fits_into_int32($val->dt, $val)" => (x86_mov dt=TB_TYPE_MEMORY $ctrl $mem $lhs flags="OP_IMMEDIATE" mode=MODE_ST extra_dt="n->inputs[3]->dt" imm="as_int32($val)")

#define NORMIE_OP(op_name, mnemonic) \
(node mnemonic X86MemOp) \
pat (op_name dt=$dt ___ $lhs $rhs) => (x86_ ## mnemonic dt=$dt ___ ___ $rhs $lhs) \
pat (op_name dt=$dt ___ $lhs (TB_LOAD $ctrl $mem ($rhs: x86_MEMORY ...))) => (x86_ ## mnemonic dt=$dt $ctrl $mem $rhs $lhs mode=MODE_LD) \
pat (op_name dt=$dt ___ $lhs ($rhs: TB_ICONST ...)) where "fits_into_int32($dt, $rhs)" => (x86_ ## mnemonic dt=$dt ___ ___ $lhs flags="OP_IMMEDIATE" imm="as_int32($rhs)") \
pat (op_name dt=$dt ___ $lhs ($rhs: TB_ICONST ...)) => (x86_ ## mnemonic dt=$dt ___ ___ $rhs $lhs)

#define NORMIE_OP8(op_name, mnemonic) \
(node mnemonic X86MemOp) \
pat (op_name dt=$dt ___ $lhs $rhs) => (x86_ ## mnemonic dt=$dt ___ ___ $rhs $lhs) \
pat (op_name dt=$dt ___ $lhs ($rhs: TB_ICONST ...)) where "fits_into_uint8($dt, $rhs)" => (x86_ ## mnemonic dt=$dt ___ ___ $lhs flags="OP_IMMEDIATE" imm="as_int32($rhs)")

NORMIE_OP(TB_ADD, add)
NORMIE_OP(TB_OR,  or)
NORMIE_OP(TB_AND, and)
NORMIE_OP(TB_SUB, sub)
NORMIE_OP(TB_XOR, xor)
NORMIE_OP(TB_MUL, imul)

// shifts
NORMIE_OP8(TB_SHL, shl)
NORMIE_OP8(TB_SHR, shr)
NORMIE_OP8(TB_SAR, sar)
NORMIE_OP8(TB_ROL, rol)
NORMIE_OP8(TB_ROR, ror)

(node div X86MemOp)
(node idiv X86MemOp)

pat (TB_UDIV dt=$dt ___ $lhs $rhs) => (TB_PROJ dt=$dt (x86_div dt=TB_TYPE_TUPLE ___ ___ $rhs $lhs extra_dt=$dt) index=0)
pat (TB_SDIV dt=$dt ___ $lhs $rhs) => (TB_PROJ dt=$dt (x86_div dt=TB_TYPE_TUPLE ___ ___ $rhs $lhs extra_dt=$dt) index=0)
pat (TB_UMOD dt=$dt ___ $lhs $rhs) => (TB_PROJ dt=$dt (x86_div dt=TB_TYPE_TUPLE ___ ___ $rhs $lhs extra_dt=$dt) index=1)
pat (TB_SMOD dt=$dt ___ $lhs $rhs) => (TB_PROJ dt=$dt (x86_div dt=TB_TYPE_TUPLE ___ ___ $rhs $lhs extra_dt=$dt) index=1)

// *******************************
// float ops
// *******************************
(node vmov X86MemOp)
(node vzero X86MemOp)

pat (TB_LOAD dt=$dt $ctrl $mem $addr) where "TB_IS_FLOAT_TYPE($dt) || TB_IS_VECTOR_TYPE($dt)" => (x86_vmov dt=$dt $ctrl $mem $addr mode=MODE_LD)
pat (TB_LOAD dt=$dt $ctrl $mem ($lhs: x86_MEMORY ...)) where "TB_IS_FLOAT_TYPE($dt) || TB_IS_VECTOR_TYPE($dt)" => (x86_vmov dt=$dt $ctrl $mem $lhs mode=MODE_LD)
pat (TB_STORE $ctrl $mem $addr $val) where "TB_IS_FLOAT_TYPE(n->inputs[3]->dt) || TB_IS_VECTOR_TYPE(n->inputs[3]->dt)" => (x86_vmov dt=TB_TYPE_MEMORY $ctrl $mem $addr $val mode=MODE_ST extra_dt="n->inputs[3]->dt")
pat (TB_STORE $ctrl $mem ($lhs: x86_MEMORY ...) $val) where "TB_IS_FLOAT_TYPE(n->inputs[3]->dt) || TB_IS_VECTOR_TYPE(n->inputs[3]->dt)" => (x86_vmov dt=TB_TYPE_MEMORY $ctrl $mem $lhs $val mode=MODE_ST extra_dt="n->inputs[3]->dt")

// float constants goop
pat (TB_F32CONST $root) where "is_float_zero(n)" => (x86_vzero dt=TB_TYPE_F32 $root)
pat (TB_F32CONST $root) => (x86_vmov dt=TB_TYPE_F32 ___ ___ (TB_MACH_SYMBOL $root sym="gimme_float_sym(ctx, n)") mode=MODE_LD)

pat (TB_F64CONST $root) where "is_float_zero(n)" => (x86_vzero dt=TB_TYPE_F64 $root)
pat (TB_F64CONST $root) => (x86_vmov dt=TB_TYPE_F64 ___ ___ (TB_MACH_SYMBOL $root sym="gimme_float_sym(ctx, n)") mode=MODE_LD)

pat (TB_VBROADCAST dt=$dt ___ ($x: TB_F32CONST $root)) where "is_float_zero($x)" => (x86_vzero dt=$dt $root)
pat (TB_VBROADCAST dt=$dt ___ ($x: TB_F32CONST $root)) => (x86_vmov dt=$dt ___ ___ (TB_MACH_SYMBOL $root sym="gimme_float_sym(ctx, n)") mode=MODE_LD)

#define FLOATIE_OP(op_name, mnemonic) \
(node mnemonic X86MemOp) \
pat (op_name dt=$dt ___ $lhs $rhs) => (x86_ ## mnemonic dt=$dt ___ ___ $rhs $lhs)

FLOATIE_OP(TB_FADD, vadd)
FLOATIE_OP(TB_FSUB, vsub)
FLOATIE_OP(TB_FMUL, vmul)
FLOATIE_OP(TB_FDIV, vdiv)
FLOATIE_OP(TB_FMAX, vmax)
FLOATIE_OP(TB_FMIN, vmin)

// *******************************
// casting
// *******************************
(node movsx8 X86MemOp)
(node movzx8 X86MemOp)
(node movsx16 X86MemOp)
(node movzx16 X86MemOp)
(node movsx32 X86MemOp)

(node vxor X86MemOp)
pat (TB_FNEG dt=$dt ___ $src)
=> (x86_vxor dt=$dt ___ ___ (TB_MACH_SYMBOL "f->root_node" sym="gimme_float_neg_zero(ctx, $dt)") $src mode=MODE_LD)

pat (TB_BITCAST dt=$dt ___ $src)
=> (TB_MACH_COPY dt=$dt ___ $src def="ctx->normie_mask[TB_IS_FLOAT_TYPE(n->dt) ? REG_CLASS_XMM : REG_CLASS_GPR]" use="ctx->normie_mask[TB_IS_FLOAT_TYPE($src->dt) ? REG_CLASS_XMM : REG_CLASS_GPR]")

pat (TB_TRUNCATE dt=$dt ___ $src)
=> (TB_MACH_COPY dt=$dt ___ $src def="ctx->normie_mask[REG_CLASS_GPR]" use="ctx->normie_mask[REG_CLASS_GPR]")

// 32 -> 64
pat (TB_SIGN_EXT dt=$dt ___ $src)
where "$dt.type == TB_TAG_I64 && n->inputs[1]->dt.type == TB_TAG_I32"
=> (x86_movsx32 dt=TB_TYPE_I64 ___ ___ $src)

// 32 -> 64
pat (TB_ZERO_EXT dt=$dt ___ $src)
where "$dt.type == TB_TAG_I64 && n->inputs[1]->dt.type == TB_TAG_I32"
=> (x86_mov dt=TB_TYPE_I64 ___ ___ $src)

// 1/8 -> 32/64
pat (TB_SIGN_EXT dt=$dt ___ $src)
where "($dt.type == TB_TAG_I32 || $dt.type == TB_TAG_I64) && ($src->dt.type == TB_TAG_I8 || $src->dt.type == TB_TAG_BOOL)"
=> (x86_movsx8 dt=$dt ___ ___ $src)

// 1/8 -> 32/64
pat (TB_ZERO_EXT dt=$dt ___ $src)
where "($dt.type == TB_TAG_I32 || $dt.type == TB_TAG_I64) && ($src->dt.type == TB_TAG_I8 || $src->dt.type == TB_TAG_BOOL)"
=> (x86_movzx8 dt=$dt ___ ___ $src)

pat (TB_ZERO_EXT dt=$dt ___ ($src: TB_LOAD $ctrl $mem $addr))
where "($dt.type == TB_TAG_I32 || $dt.type == TB_TAG_I64) && ($src->dt.type == TB_TAG_I8 || $src->dt.type == TB_TAG_BOOL)"
=> (x86_movzx8 dt=$dt $ctrl $mem $addr mode=MODE_LD)

pat (TB_ZERO_EXT dt=$dt ___ ($src: TB_LOAD $ctrl $mem ($addr: x86_MEMORY ...)))
where "($dt.type == TB_TAG_I32 || $dt.type == TB_TAG_I64) && ($src->dt.type == TB_TAG_I8 || $src->dt.type == TB_TAG_BOOL)"
=> (x86_movzx8 dt=$dt $ctrl $mem $addr mode=MODE_LD)
#endif

// *******************************
// Skylake pipeline
// *******************************
(pipeline Skylake
    // 1 "complex" decoder, 3 simple decoders
    (unit DecodeS)
    (unit DecodeC)

    // 8 execution units, addressed by the p012 syntax (meaning "ports 0, 1 or 2")
    ports=8
)

(inst_class IntOp1 "p0156*1")

// use IntOp1 if we're an add
(inst_reserve IntOp1 (x86_add ... mode=$mode) where="mode == MODE_LD")
